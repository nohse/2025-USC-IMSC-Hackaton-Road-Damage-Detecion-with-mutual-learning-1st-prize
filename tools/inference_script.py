from ultralytics import YOLO
import argparse
import os
import torch
import csv
import urllib.request

def download_if_missing(model_name):
    model_urls = {
        "yolov10s.pt": "https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10s.pt",
        "yolov10m.pt": "https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10m.pt",
        "yolov10l.pt": "https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10l.pt",
    }

    if model_name not in model_urls:
        print(f"âš ï¸ {model_name} is not a recognized YOLOv10 model, skipping download.")
        return

    if not os.path.exists(model_name):
        print(f"ğŸ”„ Downloading {model_name} ...")
        urllib.request.urlretrieve(model_urls[model_name], model_name)
        print(f"âœ… {model_name} downloaded.")
    else:
        print(f"âœ… {model_name} already exists.")

def export_tensor(pt_path):
    model = YOLO(pt_path)
    model.export(
        imgsz=224,
        format="engine",
        dynamic=False,
        batch=8,
        workspace=10,
        half=True,
        int8=False,
        data="train_full_pseudo.yaml",
        device=[0],
        opset=12,
    )

# Setup
torch.cuda.empty_cache()
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Parse arguments
parser = argparse.ArgumentParser(description='YOLO Inference Script')
parser.add_argument('--model-file', type=str, help='model file name including directory name')
parser.add_argument('--source-path', type=str, help='Path to the directory containing images for inference')
parser.add_argument('--output-file', type=str, help='output CSV file name including directory name')
parser.add_argument('--engine', action='store_true', help='export tensorrt engine')
args = parser.parse_args()

# Load the YOLO model
model_path = "/home/sejong/seonghyeon/road_damage_detection/runs/detect/pretrain/weights/epoch75.pt"#ì´ê°€ì€

# âœ… ìë™ ë‹¤ìš´ë¡œë“œ
download_if_missing(os.path.basename(model_path))

if args.engine:
    engine_path = model_path.replace('.pt', '.engine')
    if not os.path.exists(engine_path):
        print('ğŸš€ Exporting to TensorRT engine...')
        export_tensor(model_path)
    print(f"[!] TensorRT export done, but note: Ultralytics 'YOLO()' cannot load '.engine' directly.")
    # model_path = engine_path  # ì£¼ì„ ìœ ì§€: .engine ë¡œë“œ ë¶ˆê°€ëŠ¥

# ëª¨ë¸ ë¡œë”©
net = YOLO(model_path)

# ì´ë¯¸ì§€ ì¶”ë¡  ê²½ë¡œ
source_path = "/home/sejong/seonghyeon/road_damage_detection/yolodata/test/images"#ì´ê°€ì€

# Run inference
results = net.predict(
    source=source_path,
    device=0,
    conf=0.30,#ì´ê°€ì€
    max_det=20,
    augment=False,
    imgsz=640,
    classes=[0,1,2,3],
    batch=4,
    half=True
)

import os
import csv

# ê²°ê³¼ CSV ì €ì¥ ê²½ë¡œ
csv_file_path = "/home/sejong/seonghyeon/road_damage_detection/output/charmander_yolo8mmutual-tunedcort-0.30.csv"#ì´ê°€ì€

# 1) ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ìœ¼ë©´)
os.makedirs(os.path.dirname(csv_file_path), exist_ok=True)

# 2) íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ë¡œ ëª¨ë“œ ê²°ì •
file_exists = os.path.isfile(csv_file_path)
mode = 'a' if file_exists else 'w'

with open(csv_file_path, mode=mode, newline='') as csvfile:
    csv_writer = csv.writer(csvfile)
    
    # 3) ìƒˆë¡œ ë§Œë“¤ ë•Œë§Œ í—¤ë” ì‘ì„±
    if not file_exists:
        csv_writer.writerow(['ImageId', 'PredictionString'])
    
    # 4) ì˜ˆì¸¡ ê²°ê³¼ë¥¼ íŒŒì¼ì— ê¸°ë¡
    for result in results:
        image_path = result.path
        image_name = os.path.basename(image_path)

        prediction_string = ""
        labels = result.boxes.cls.cpu().numpy()
        boxes = result.boxes.xyxy.cpu().numpy()

        for label, box in zip(labels, boxes):
            x_min, y_min, x_max, y_max = map(int, box)
            prediction_string += f"{int(label)} {x_min} {y_min} {x_max} {y_max} "

        csv_writer.writerow([image_name, prediction_string.strip()])

print(f"âœ… Predictions saved to: {csv_file_path}")
import os

# 5) baseline í´ë” ìƒì„±
csv_dir = os.path.dirname(csv_file_path)
txt_dir = os.path.join(csv_dir, 'baseline')
os.makedirs(txt_dir, exist_ok=True)

# 6) results ìˆœíšŒí•˜ë©° txt ìƒì„± (í•œ ì¤„ì— í•˜ë‚˜ì˜ detection)
for result in results:
    image_name = os.path.basename(result.path)
    image_id   = os.path.splitext(image_name)[0]

    # countryë³„ ì´ë¯¸ì§€ í¬ê¸° ì„¤ì •
    if image_name.startswith('country1_'):
        size = 720
    elif image_name.startswith('country2_'):
        size = 600
    elif image_name.startswith('country3_'):
        size = 640
    else:
        size = max(result.orig_shape[1], result.orig_shape[0])

    labels = result.boxes.cls.cpu().numpy()
    boxes  = result.boxes.xyxy.cpu().numpy()
    confs  = result.boxes.conf.cpu().numpy()

    txt_lines = []
    for lbl, box, conf in zip(labels, boxes, confs):
        x_min, y_min, x_max, y_max = box.astype(float)
        x_c = ((x_min + x_max) / 2) / size
        y_c = ((y_min + y_max) / 2) / size
        w   = (x_max - x_min) / size
        h   = (y_max - y_min) / size
        txt_lines.append(f"{int(lbl)} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f} {conf:.6f}")


    # ì´ì œ ê° detectionì„ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•´ íŒŒì¼ì— ì”ë‹ˆë‹¤.
    txt_path = os.path.join(txt_dir, f"{image_id}.txt")
    with open(txt_path, 'w') as f:
        f.write("\n".join(txt_lines))

print(f"âœ… Text files saved to: {txt_dir}")

